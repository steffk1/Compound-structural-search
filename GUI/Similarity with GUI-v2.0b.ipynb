{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c5a077-8222-4cfb-b899-aa8fbc4e8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following modules need to be installed to run this script:\n",
    "# rdkit, pandas, scipy, matplotlib, openpyxl, and numpy\n",
    "# To install rdkit for Jupyter Lab, open a command prompt and type \"pip install rdkit\"\n",
    "# Repeat \"pip install ___\" for each of the other modules listed above.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "#############################################\n",
    "############################################\n",
    "############################################\n",
    "\n",
    "import tkinter as tk\n",
    "import os\n",
    "from tkinter import *\n",
    "from tkinter import filedialog as fd\n",
    "from tkinter.messagebox import showinfo\n",
    "\n",
    "import io\n",
    "from io import StringIO\n",
    "\n",
    "import ntpath\n",
    "import time\n",
    "import sys, math\n",
    "\n",
    "# Function to calculate Tanimoto similarity\n",
    "def calculate_tanimoto(fp1, fp2):\n",
    "    return DataStructs.FingerprintSimilarity(fp1, fp2)\n",
    "\n",
    "\n",
    "## _____INPUTS_window__________Take in all of the parameters\n",
    "root= tk.Tk()\n",
    "root.title(\"      Structure Similarity Search\")\n",
    "btn20 = StringVar()\n",
    "\n",
    "ent1 = tk.Entry(root,font='serif 10')\n",
    "ent1.grid(row=2,column=1,ipadx=70,sticky=W+E)\n",
    "\n",
    "ent2 = tk.Entry(root,font='serif 10')\n",
    "ent2.grid(row=4,column=1,ipadx=70,sticky=W+E)\n",
    "\n",
    "root.lift()\n",
    "root.attributes('-topmost',True)\n",
    "root.after_idle(root.attributes,'-topmost',False)\n",
    "\n",
    "def select_MiBiG():\n",
    "    global MiBiG_directory\n",
    "    global MiBiG_filepath\n",
    "    global MiBiG_filename\n",
    "    global MiBiG_filepath_trim\n",
    "        \n",
    "    filetypes1 = ((\"CSV files\", '*.csv'),(\"All files\", '*.*'))\n",
    "\n",
    "    MiBiG_filepath = fd.askopenfilename(\n",
    "        title=\"Open MiBiG file\",\n",
    "        initialdir='/Users/', #Add the path to your working directory here to save time in future runs of the program\n",
    "        filetypes=filetypes1)\n",
    "    MiBiG_filename = ntpath.basename(MiBiG_filepath)\n",
    "    ent1.insert(tk.END, MiBiG_filename)\n",
    "    print(MiBiG_filepath,\"\\n\")\n",
    "    MiBiG_directory = ntpath.dirname(MiBiG_filepath[0])\n",
    "    MiBiG_filepath_trim = MiBiG_filepath[:-4] #Removes \".csv\" from filepath to get the filename.\n",
    "    \n",
    "def get_SMILES():\n",
    "    global SMILES_directory\n",
    "    global SMILES_filepath\n",
    "    global SMILES_filename\n",
    "    global SMILES_filepath_trim\n",
    "    global SMILES_data\n",
    "    \n",
    "    filetypes2 = ((\"XLSX files\", '*.xlsx'),(\"XLS files\", '*.xls'),(\"All files\", '*.*'))\n",
    "    \n",
    "    SMILES_filepath = fd.askopenfilename(\n",
    "        title=\"Open file(s)\",\n",
    "        initialdir='/Users/', #Add the path to your working directory here to save time in future runs of the program\n",
    "        filetypes=filetypes2)\n",
    "    SMILES_filename = ntpath.basename(SMILES_filepath)\n",
    "    ent2.insert(tk.END, SMILES_filename)\n",
    "    SMILES_directory = ntpath.dirname(SMILES_filepath)\n",
    "    SMILES_filepath_trim = SMILES_filepath[:-5] #Removes \".xlsx\" from filepath to get the filename.\n",
    "    SMILES_data = pd.read_excel (SMILES_filepath, engine='openpyxl')\n",
    "    \n",
    "def Button_fun():\n",
    "    global Dendro_count\n",
    "    global SMILES_count\n",
    "    global Sim_hits\n",
    "    global Create_dendro\n",
    "    \n",
    "    Sim_hits = entry07.get()\n",
    "    Create_dendro = btn20.get()\n",
    "    Dendro_count = entry22.get()\n",
    "\n",
    "    def isfloat(value):\n",
    "        try:\n",
    "            float(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def is_int(value):\n",
    "        try:\n",
    "            int(value)\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    if Dendro_count == \"\": #for when there is no input, it designates a default value\n",
    "        Dendro_count = 20\n",
    "    elif ((type(Dendro_count) == str) & (is_int(Dendro_count) == True)):\n",
    "        Dendro_count = int(Dendro_count)\n",
    "    else:\n",
    "        print(Dendro_count, \" is an invalid entry.  Try again.\")\n",
    "\n",
    "    if Sim_hits == \"\": #for when there is no input, it designates a default value\n",
    "        Sim_hits = 10\n",
    "    elif ((type(Sim_hits) == str) & (is_int(Sim_hits) == True)):\n",
    "        Sim_hits = int(Sim_hits)\n",
    "    else:\n",
    "        print(Sim_hits, \" is an invalid entry.  Try again.\")\n",
    "\n",
    "    root.destroy()\n",
    "\n",
    "\n",
    "###### All operations should be above this line\n",
    "#### Start of the GUI ####\n",
    "Gap01 = Label(root)\n",
    "Gap01.grid(row=1, columnspan=3)\n",
    "\n",
    "cmpd_button=tk.Button(root,text=\"     MiBiG file (*.csv)     \", bg='green', fg='white', command=select_MiBiG)\n",
    "cmpd_button.grid(row=2, sticky=E, padx=7)\n",
    "Gap03= Label(root)\n",
    "Gap03.grid(row=3, columnspan=3)\n",
    "\n",
    "cmpd_button=tk.Button(root,text=\"     SMILES file (*.xlsx)     \", bg='green', fg='white', command=get_SMILES)\n",
    "cmpd_button.grid(row=4, sticky=E, padx=7)\n",
    "Gap05 = Label(root)\n",
    "Gap05.grid(row=5, columnspan=3)\n",
    "\n",
    "label07 = Label(root, text=\"Number of similar compounds for data table (default = 10): \")\n",
    "label07.grid(row=7, column=0, sticky=E)\n",
    "entry07 = Entry(root)\n",
    "entry07.grid(row=7, column=1, pady=2, sticky=W)\n",
    "\n",
    "Gap10 = Label(root)\n",
    "Gap10.grid(row=10, columnspan=3)\n",
    "labelS2 = Label(root, text=\"____________________Special processing settings______________________\")\n",
    "labelS2.grid(row=11)\n",
    "\n",
    "label20 = Label(root, text=\"Create a dendrogram for each input compound?\")\n",
    "label20.grid(row=20, column=0, sticky=E)\n",
    "btn20.set(\"no\")\n",
    "button20=Radiobutton(root,text=\"Yes\",value = \"yes\",variable = btn20).grid(row=21, column=0, sticky=E)\n",
    "button20=Radiobutton(root,text=\"No\",value = \"no\",variable = btn20).grid(row=21, column=1, sticky=W)\n",
    "\n",
    "label22 = Label(root, text=\"Similarity count for dendrogram (default = 20): \")\n",
    "label22.grid(row=24, column=0, sticky=E)\n",
    "entry22 = Entry(root)\n",
    "entry22.grid(row=24, column=1, pady=2, sticky=W)\n",
    "\n",
    "Gap37 = Label(root)\n",
    "Gap37.grid(row=37, columnspan=3)\n",
    "\n",
    "CMPD_LIST = Button(root, text=\"     Start processing     \", fg='black', bg='lightsteelblue2', relief='raised', command=Button_fun)\n",
    "CMPD_LIST.grid(row=38, columnspan=3)\n",
    "\n",
    "Gap39 = Label(root)\n",
    "Gap39.grid(row=39, columnspan=3)\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "#### End of the GUI ####\n",
    "#### ----------------------------- Above are all the data inputs --------------\n",
    "\n",
    "start_time = time.time()  ## Start of time function to measure how long processing takes\n",
    "\n",
    "SMILES_avail = len(SMILES_data)  ## Computes how many compounds are in the imported compounds table\n",
    "SMILES_count = SMILES_avail ## Auto set this value to search for all\n",
    "\n",
    "#########################################\n",
    "#########################################\n",
    "##########################################\n",
    "print(\"Similarity hits: \",Sim_hits)\n",
    "print(\"Dendro_count: \",Dendro_count)\n",
    "print(\"Create dendrogram?: \",Create_dendro)\n",
    "\n",
    "#### ----------------------------- Start of fingerprinting -------- Need function to load existing FNGPRT file if already computed before------\n",
    "FNGPRT_filepath = MiBiG_filepath_trim + \".fngprt\" # Fingerprint file name for output\n",
    "print(\"Fingerprint data path: \\n\",FNGPRT_filepath)\n",
    "\n",
    "if os.path.exists(FNGPRT_filepath): ##If a \".fngprt\" file exists, it will be loaded\n",
    "    data_MiBiG = pd.read_csv(FNGPRT_filepath, sep='\\t') ## Opens the existing \".fngprt\" file as a CSV file (tab delimited)\n",
    "    print(\"\\nFingerprint_df shape: \",data_MiBiG.shape)\n",
    "    print(\"\\nFingerprint file already exists and has been loaded:\\n %s \\n\" % (FNGPRT_filepath))\n",
    "else:\n",
    "    data_MiBiG = pd.read_csv(MiBiG_filepath, sep='\\t', header=None, names=['SMILES', 'Name']) ## Opens MIBig CSV file (tab delimited)\n",
    "    print(\"Input accepted for MiBiG file:\\n  %s \\n\" % (MiBiG_filename))\n",
    "    print(\"data_MiBiG shape\",data_MiBiG.shape,\"\\n\")\n",
    "   \n",
    "    #2 Check SMILES\n",
    "    # Assuming data_MiBiG is your DataFrame with 'SMILES' column\n",
    "    data_MiBiG['Molecule'] = data_MiBiG['SMILES'].apply(Chem.MolFromSmiles)\n",
    "    # Check for invalid SMILES\n",
    "    invalid_smiles = data_MiBiG[data_MiBiG['Molecule'].isnull()]\n",
    "    # Display invalid SMILES, if any\n",
    "    if(len(invalid_smiles)>0):\n",
    "        print(\"Invalid SMILES: \",invalid_smiles[['SMILES', 'Name']])\n",
    "    # Add a new column for fingerprints\n",
    "    data_MiBiG['Fingerprint'] = data_MiBiG['SMILES'].apply(lambda x: AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(x), 2, nBits=2048))\n",
    "    # Convert fingerprints to binary strings\n",
    "    data_MiBiG['Fingerprint'] = data_MiBiG['Fingerprint'].apply(lambda x: x.ToBitString())\n",
    "    data_MiBiG.to_csv(FNGPRT_filepath, sep='\\t', header=True, index = False)  ## WRITE Results for if there was only 1 input file\n",
    "    print(\"Fingerprint file saved as: \\n\", FNGPRT_filepath)\n",
    "\n",
    "    \n",
    "#### ----------------------------- Add compounds to search for --------------\n",
    "\n",
    "#Generate fingerprint for search compounds, then append them to main table\n",
    "#Drop unnecessary columns from SMILES file\n",
    "columns_to_keep = ['SMILES', 'Name']\n",
    "columns_to_drop = [col for col in SMILES_data.columns if col not in columns_to_keep]\n",
    "SMILES_data = SMILES_data.drop(columns=columns_to_drop)\n",
    "print(\"Smiles_data shape:\\n\",SMILES_data.shape)\n",
    "SMILES_data['Name'] = \"__\" + SMILES_data['Name'].astype(str) ##Adds \"__\" to compound names to add tabs in output for alignment\n",
    "SMILES_data['Molecule'] = SMILES_data['SMILES'].apply(Chem.MolFromSmiles)\n",
    "SMILES_data['Fingerprint'] = SMILES_data['SMILES'].apply(lambda x: AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(x), 2, nBits=2048))\n",
    "SMILES_data['Fingerprint'] = SMILES_data['Fingerprint'].apply(lambda x: x.ToBitString())\n",
    "\n",
    "\n",
    "#5 Let's add our experimental structure to one of the data frames\n",
    "SMILES_len = len(SMILES_data)\n",
    "data_MiBiG = pd.concat([data_MiBiG, SMILES_data], ignore_index=True) ### Concatenate SMILES_data to data_MiBiG\n",
    "\n",
    "Mid1_time = time.time()  ## Start of dendrogram function to measure how long dendrogram takes\n",
    "print(\"\\n\\n---Time to complete fingerprinting: %s seconds ---\" % (Mid1_time - start_time))  ## Indicates amount of time it took after inputs were given\n",
    "\n",
    "\n",
    "#### ----------------------------- Similarity calculations --------------\n",
    "                \n",
    "#8 2. Calculate Tanimoto Similarity Matrix\n",
    "# Create a similarity matrix\n",
    "similarity_matrix = []\n",
    "\n",
    "for i in range(len(data_MiBiG)):\n",
    "    row_similarities = []\n",
    "    for j in range(len(data_MiBiG)):\n",
    "        fp1 = DataStructs.CreateFromBitString(data_MiBiG.iloc[i]['Fingerprint'])\n",
    "        fp2 = DataStructs.CreateFromBitString(data_MiBiG.iloc[j]['Fingerprint'])\n",
    "        similarity = calculate_tanimoto(fp1, fp2)\n",
    "        row_similarities.append(similarity)\n",
    "    similarity_matrix.append(row_similarities)\n",
    "\n",
    "similarity_df=pd.DataFrame(similarity_matrix)\n",
    "\n",
    "#11Let's set row and column names for convenience\n",
    "similarity_df.columns = data_MiBiG[\"Name\"]  # Set columns names\n",
    "similarity_df.index = data_MiBiG[\"Name\"]    # Set row names\n",
    "\n",
    "similarity_length = len(similarity_df) -1\n",
    "\n",
    "####______Multiple compound loop starts here.  Create dataframe of results and append to a master_df. Dendro output per loop\n",
    "Mid2_time = time.time()  ## Start of similarity tabulation function to measure how long dendrogram takes\n",
    "print(\"\\n\\n---Time to complete similarity matrix: %s seconds ---\" % (Mid2_time - Mid1_time))  ## Indicates amount of time it took after inputs were given\n",
    "\n",
    "for cmpd_loop in range(0, SMILES_len):\n",
    "    Cmpd_address = similarity_length - SMILES_count + cmpd_loop + 1\n",
    "    cmpd_name = SMILES_data.iat[(cmpd_loop),0]\n",
    "    sim_temp = pd.DataFrame(similarity_df)[:].copy(deep=True)\n",
    "    \n",
    "    #### ----------------------------- Similarity output function --------------\n",
    "    # Which compounds is \"our compound\" most similar to?\n",
    "    row_values = similarity_df.iloc[Cmpd_address]\n",
    "    top_X = row_values.nlargest(Sim_hits)\n",
    "    if cmpd_loop == 0:\n",
    "        topX_df = top_X.to_frame()\n",
    "        topX_df.insert(len(topX_df.columns), \"Compound_name\", topX_df.index)\n",
    "        topX_df = topX_df.rename(columns={topX_df.columns[0]: \"Similarity\"})\n",
    "        Output_data = topX_df\n",
    "        Output_data.loc[len(Output_data)] = [np.nan] * len(Output_data.columns)\n",
    "        Output_data.loc[len(Output_data)] = [np.nan] * len(Output_data.columns)\n",
    "        Output_data.loc[len(Output_data)] = [np.nan] * len(Output_data.columns)\n",
    "\n",
    "        add_rows = range(0, Sim_hits + 3)\n",
    "        sequence_of_rows = []\n",
    "        for number in add_rows:\n",
    "            sequence_of_rows.append(number)  ## Adds columns proportionate to how many are needed\n",
    "        \n",
    "        Output_data.index = sequence_of_rows\n",
    "        del topX_df\n",
    "    else:\n",
    "        topX_df = top_X.to_frame()\n",
    "        topX_df.insert(len(topX_df.columns), \"Compound_name\", topX_df.index)\n",
    "        topX_df = topX_df.rename(columns={topX_df.columns[0]: \"Similarity\"})\n",
    "        topX_df.loc[len(topX_df)] = [np.nan] * len(topX_df.columns)\n",
    "        topX_df.loc[len(topX_df)] = [np.nan] * len(topX_df.columns)\n",
    "        topX_df.loc[len(topX_df)] = [np.nan] * len(topX_df.columns)\n",
    "        \n",
    "        add_rows = range(len(Output_data), (len(Output_data))+Sim_hits+3)\n",
    "        sequence_of_rows = []\n",
    "        for number in add_rows:\n",
    "            sequence_of_rows.append(number)  ## Adds columns proportionate to how many are needed\n",
    "        \n",
    "        topX_df.index = sequence_of_rows\n",
    "        Output_data = pd.concat([Output_data,topX_df])\n",
    "        del topX_df\n",
    "    \n",
    "    #### ----------------------------- Dendrogram creation function --------------\n",
    "    if Create_dendro == \"yes\": #### Sorts data by peak area to put biggest hits at top\n",
    "        ##THIS IS THE FUNCTION TO REMOVE VALUES BELOW \"Dendro_count\" FROM similarity_df\n",
    "        sim_temp = sim_temp.rename(columns={sim_temp.columns[Cmpd_address]: \"SM_column\"})\n",
    "        sim_temp = sim_temp.sort_values(by=\"SM_column\", ascending=False)\n",
    "        sim_temp = sim_temp.iloc[:Dendro_count]\n",
    "        similarity_matrix = sim_temp.values.tolist() ##Convert the shortened dataframe back to a list format\n",
    "        sim_temp['Name'] = sim_temp.index #Create a Name column containing the index values, which are the names\n",
    "        #### ----------------------------- Clustering function --------------\n",
    "        # Perform hierarchical clustering\n",
    "        cluster_data = linkage(similarity_matrix, method='average', metric='euclidean')\n",
    "        #### ----------------------------- Creation and output of Dendrogram --------------\n",
    "        dendro_length = len(sim_temp) -1\n",
    "        wide = 10\n",
    "        tall = int(dendro_length/4) +1\n",
    "        # Plot dendrogram\n",
    "        plt.figure(figsize=(wide, tall))\n",
    "        dendrogram(cluster_data, labels=sim_temp['Name'].tolist(), orientation='right', leaf_font_size=10)\n",
    "        plt.title('Molecule Clustering based on Tanimoto Similarity')\n",
    "        Dendro_Output_Filename = SMILES_directory+\"/Compound dendrograms/Closest-\"+str(dendro_length)+\" hits_\"+str(cmpd_name)+\".pdf\"\n",
    "        Dendro_path = SMILES_directory+\"/Compound dendrograms\"\n",
    "        os.makedirs(Dendro_path, exist_ok=True)\n",
    "        plt.savefig(Dendro_Output_Filename, format='pdf', bbox_inches='tight')\n",
    "        print(\"\\nFilename: \",Dendro_Output_Filename) #Saves dendrogram as a PDF with the name of the compound as the file name\n",
    "    del sim_temp\n",
    "    del top_X    \n",
    "    cmpd_loop +=1\n",
    "    \n",
    "print(\"Output data shape: \",Output_data.shape)\n",
    "\n",
    "##Reformatting of output dataframe and output to a TSV (tab separated values) file.  TSV versus CSV as compound names can have commas in them.\n",
    "Output_string = Output_data.to_csv(sep='\\t', header=False, index = False)\n",
    "Output_string = Output_string.replace(\"_\", \"\\t\")\n",
    "Output_data = pd.read_csv(io.StringIO(Output_string), sep=\"\\t\", header=None, names=['Similarity','BGC','MIBig','Compound_name'])\n",
    "Output_data = Output_data.drop([\"MIBig\"], axis=1)\n",
    "Output_data[\"Similarity\"].round(decimals = 3)\n",
    "\n",
    "Output_filepath = SMILES_filepath_trim + \"__Top_\" + str(Sim_hits) + \"hits_Results.tsv\" # Creation of output filename\n",
    "Output_data.to_csv(Output_filepath, sep='\\t', header=True, index = False) #Using \\t to output in TSV format\n",
    "\n",
    "#### ----------------------------- Final timer wrapup --------------\n",
    "print(\"\\n\\n---Time to make fingerprints: %s seconds ---\" % (Mid1_time - start_time))  ## Indicates amount of time it took after inputs were given\n",
    "print(\"---Time to make similarity matrix: %s seconds ---\" % (Mid2_time - Mid1_time))  ## Indicates amount of time it took after inputs were given\n",
    "print(\"\\n---Total processing took: %s seconds ---\" % (time.time() - start_time))  ## Indicates amount of time it took after inputs were given\n",
    "print(\"\\n---A total of %s compounds were analyzed ---\" % (SMILES_len))  ## Indicates amount of time it took after inputs were given\n",
    "\n",
    "## https://github.com/rdkit/rdkit/issues/7625 is about deprecation issue with AllChem.GetMorganFingerprintAsBitVect error messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
